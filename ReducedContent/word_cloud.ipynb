{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tqdm_notebook(range(len(df))):\n",
    "    i = df['ID'][t]\n",
    "    path = f'Centrality Results/word_cloud/{i}/'\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    dict = json.loads(df['common_centralities'][t].replace(\"'\", \"\\\"\"))\n",
    "    if(len(list(dict.keys())) < 1):\n",
    "        continue\n",
    "    dd_dict = {}\n",
    "    ndtv_dict = {}\n",
    "    tn_dict = {}\n",
    "    for keys in dict.keys():\n",
    "        dd_dict[keys] = dict[keys][0]*100\n",
    "        ndtv_dict[keys] = dict[keys][1]*100\n",
    "        tn_dict[keys] = dict[keys][2]*100\n",
    "\n",
    "    dd_tn = ast.literal_eval(df['dd_tn'][t])\n",
    "    dd_ndtv = ast.literal_eval(df['dd_ndtv'][t])\n",
    "    ndtv_dd = ast.literal_eval(df['ndtv_dd'][t])\n",
    "    ndtv_tn = ast.literal_eval(df['ndtv_tn'][t])\n",
    "    tn_dd = ast.literal_eval(df['tn_dd'][t])\n",
    "    tn_ndtv = ast.literal_eval(df['tn_ndtv'][t])\n",
    "\n",
    "    for words in dd_tn:\n",
    "        dd_dict[words[0]] = words[1]*100\n",
    "    for words in dd_ndtv:\n",
    "        dd_dict[words[0]] = words[1]*100\n",
    "\n",
    "    for words in ndtv_dd:\n",
    "        ndtv_dict[words[0]] = words[1]*100\n",
    "    for words in ndtv_tn:\n",
    "        ndtv_dict[words[0]] = words[1]*100\n",
    "\n",
    "    for words in tn_dd:\n",
    "        tn_dict[words[0]] = words[1]*100\n",
    "    for words in tn_ndtv:\n",
    "        tn_dict[words[0]] = words[1]*100\n",
    "\n",
    "\n",
    "    ndtv_dict = {keys:ndtv_dict[keys] + 2 for keys in ndtv_dict.keys()}\n",
    "    dd_dict = {keys:dd_dict[keys] + 2 for keys in dd_dict.keys()}\n",
    "    tn_dict = {keys:tn_dict[keys] + 2 for keys in tn_dict.keys()}\n",
    "\n",
    "    wordcloud_dd = WordCloud(max_words=500, background_color=\"white\",height = 500,width = 500,scale=5,relative_scaling=0.5,min_font_size=1,prefer_horizontal=1).generate_from_frequencies(dd_dict)\n",
    "    wordcloud_ndtv = WordCloud(max_words=500, background_color=\"white\",height = 500,width = 500,scale=5,relative_scaling=0.5,min_font_size=1,prefer_horizontal=1).generate_from_frequencies(ndtv_dict)\n",
    "    wordcloud_tn = WordCloud(max_words=500, background_color=\"white\",height = 500,width = 500,scale=5,relative_scaling=0.5,min_font_size=1,prefer_horizontal=1).generate_from_frequencies(tn_dict)\n",
    "    \n",
    "    \n",
    "    os.makedirs(path,exist_ok=True)\n",
    "    wordcloud_dd.to_file(path + 'dd.jpg')\n",
    "    wordcloud_ndtv.to_file(path + 'ndtv.jpg')\n",
    "    wordcloud_tn.to_file(path + 'tn.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
